from typing import List, Tuple, Dict, Optional
from sqlalchemy.orm import Session
from sqlalchemy import and_, tuple_
from app.models.elevation import ElevationCache
from app.core.exceptions import ExternalAPIException
import httpx
import logging
import asyncio
import os
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)

logger = logging.getLogger(__name__)

# SRTM ë°ì´í„° (ëª¨ë“ˆ ë ˆë²¨ì—ì„œ 1íšŒë§Œ ì´ˆê¸°í™”, ì´í›„ ì¬ì‚¬ìš©)
_srtm_data = None

def _get_srtm_data():
    """SRTM ë°ì´í„°ë¥¼ ì‹±ê¸€í„´ìœ¼ë¡œ ë¡œë“œ"""
    global _srtm_data
    if _srtm_data is None:
        try:
            import srtm
            _srtm_data = srtm.get_data()
            logger.info("âœ… SRTM ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ SRTM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. Open-Meteo fallback ì‚¬ìš©.")
    return _srtm_data

class ElevationService:
    """ê³ ë„ ë°ì´í„° ì¡°íšŒ ì„œë¹„ìŠ¤ (SRTM ìš°ì„  â†’ ìºì‹œ â†’ API fallback)"""
    
    # ì„œìš¸ì‹œ ê²½ê³„ (ì•ˆì „ ì—¬ìœ  í¬í•¨)
    SEOUL_BOUNDS = {
        'lat_min': 37.4,
        'lat_max': 37.7,
        'lon_min': 126.7,
        'lon_max': 127.2
    }
    
    # ìºì‹œ ê²€ìƒ‰ í—ˆìš© ì˜¤ì°¨ (ì•½ 11m)
    CACHE_TOLERANCE = 0.0001
    
    def __init__(self, db: Session):
        self.db = db
        self._client = None
        self._srtm = _get_srtm_data()
    
    def _get_srtm_elevation(self, lat: float, lon: float) -> Optional[float]:
        """SRTMì—ì„œ ê³ ë„ ì¡°íšŒ (ë¡œì»¬ ë°ì´í„°)"""
        if self._srtm is not None:
            try:
                elev = self._srtm.get_elevation(lat, lon)
                if elev is not None:
                    return float(elev)
            except Exception:
                pass
        return None
    
    async def __aenter__(self):
        """Context Manager ì§„ì…: AsyncClient ìƒì„±"""
        self._client = httpx.AsyncClient(
            timeout=httpx.Timeout(10.0, connect=5.0),
            limits=httpx.Limits(max_keepalive_connections=20, max_connections=50)
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Context Manager ì¢…ë£Œ: AsyncClient ì •ë¦¬"""
        if self._client and not self._client.is_closed:
            await self._client.aclose()
        return False
    
    async def get_client(self) -> httpx.AsyncClient:
        """AsyncClient ë°˜í™˜ (Context Manager ì‚¬ìš© ì‹œ ìë™ ìƒì„±ë¨)"""
        if self._client is None or self._client.is_closed:
            self._client = httpx.AsyncClient(
                timeout=httpx.Timeout(10.0, connect=5.0),
                limits=httpx.Limits(max_keepalive_connections=20, max_connections=50)
            )
        return self._client
    
    def is_in_seoul(self, lat: float, lon: float) -> bool:
        """ì„œìš¸ì‹œ ë²”ìœ„ ë‚´ ì¢Œí‘œì¸ì§€ í™•ì¸"""
        return (
            self.SEOUL_BOUNDS['lat_min'] <= lat <= self.SEOUL_BOUNDS['lat_max'] and
            self.SEOUL_BOUNDS['lon_min'] <= lon <= self.SEOUL_BOUNDS['lon_max']
        )
    
    async def get_elevation(self, lat: float, lon: float) -> float:
        """ë‹¨ì¼ ì¢Œí‘œ ê³ ë„ ì¡°íšŒ (SRTM â†’ ìºì‹œ â†’ API ìˆœì„œ)"""
        
        # 1. SRTM ìš°ì„  ì¡°íšŒ (ë¡œì»¬, ê°€ì¥ ë¹ ë¦„)
        srtm_elev = self._get_srtm_elevation(lat, lon)
        if srtm_elev is not None:
            return srtm_elev
        
        # 2. ì„œìš¸ì‹œ ë²”ìœ„ ì²´í¬
        if not self.is_in_seoul(lat, lon):
            logger.warning(f"Coordinate out of Seoul bounds: ({lat}, {lon})")
            return await self._fetch_from_api(lat, lon)
        
        # 3. ìºì‹œ ì¡°íšŒ
        cached = self._get_from_cache(lat, lon)
        if cached:
            cached.hit_count += 1
            return float(cached.elevation)
        
        # 4. API í˜¸ì¶œ
        elevation = await self._fetch_from_api(lat, lon)
        
        # 5. ìºì‹œ ì €ì¥
        self._save_to_cache(lat, lon, elevation)
        
        return elevation
    
    async def get_elevations_batch(
        self,
        coordinates: List[Tuple[float, float]]
    ) -> Dict[Tuple[float, float], float]:
        """
        ë°°ì¹˜ ê³ ë„ ì¡°íšŒ (ê·¸ë¦¬ë”© + ë²Œí¬ íˆíŠ¸ + Nearest Neighbor Lookup + ì ì‘í˜• ìƒ˜í”Œë§)
        """
        if not coordinates:
            return {}
            
        results = {}
        
        # 1. SRTM ìš°ì„  ì¡°íšŒ (ë¡œì»¬ ë°ì´í„°, ê°€ì¥ ë¹ ë¦„)
        srtm_results = {}
        remaining_coords = []
        
        for lat, lon in coordinates:
            srtm_elev = self._get_srtm_elevation(lat, lon)
            if srtm_elev is not None:
                srtm_results[(lat, lon)] = srtm_elev
            else:
                remaining_coords.append((lat, lon))
        
        if srtm_results:
            logger.info(f"ğŸ“ SRTM ì¡°íšŒ: {len(srtm_results)}/{len(coordinates)}ê°œ ì„±ê³µ")
        
        # ê²°ê³¼ì— SRTM ë°ì´í„° ì¶”ê°€
        results.update(srtm_results)
        
        # SRTMì—ì„œ ëª» ì°¾ì€ ì¢Œí‘œë§Œ ê³„ì† ì²˜ë¦¬
        if not remaining_coords:
            return results
        
        coordinates = remaining_coords
        
        # 2. ê·¸ë¦¬ë”© (ì¢Œí‘œ ì •ê·œí™” ë° ì¤‘ë³µ ì œê±°)
        grid_map = {} 
        for lat, lon in coordinates:
            # 11m ë‹¨ìœ„ ì •ë„ëŠ” ê°™ì€ ì ìœ¼ë¡œ ì·¨ê¸‰í•´ë„ ë¬´ë°©í•˜ë¯€ë¡œ 4ìë¦¬ ë°˜ì˜¬ë¦¼
            grid_coord = (round(lat, 4), round(lon, 4))
            if grid_coord not in grid_map:
                grid_map[grid_coord] = []
            grid_map[grid_coord].append((lat, lon))
            
        unique_grids = list(grid_map.keys())
        # ì„œìš¸ì‹œ ë‚´ë¶€ ì¢Œí‘œë§Œ í•„í„°ë§
        seoul_grids = [gc for gc in unique_grids if self.is_in_seoul(*gc)]
        
        # 2. ìºì‹œ ì¡°íšŒ (Nearest Neighbor Lookup)
        # í•´ë‹¹ ì˜ì—­ì˜ ëª¨ë“  ìºì‹œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë©”ëª¨ë¦¬ì—ì„œ ê°€ê¹Œìš´ ì  ì°¾ê¸°
        cache_hits = {}
        cache_misses = []
        
        if seoul_grids:
            lats = [g[0] for g in seoul_grids]
            lons = [g[1] for g in seoul_grids]
            
            # ê²€ìƒ‰ ë²”ìœ„ ì„¤ì • (ì—¬ìœ ë¶„ í¬í•¨)
            # 0.005ë„ â‰ˆ 500m ì—¬ìœ  (ê²½ë¡œ ì£¼ë³€ ë°ì´í„°ë¥¼ ì¶©ë¶„íˆ ê°€ì ¸ì˜´)
            margin = 0.005 
            min_lat, max_lat = min(lats) - margin, max(lats) + margin
            min_lon, max_lon = min(lons) - margin, max(lons) + margin
            
            # DBì—ì„œ ë²”ìœ„ ë‚´ ëª¨ë“  ìºì‹œ ë°ì´í„° ë¡œë“œ
            cached_records = self.db.query(ElevationCache).filter(
                and_(
                    ElevationCache.latitude.between(min_lat, max_lat),
                    ElevationCache.longitude.between(min_lon, max_lon)
                )
            ).all()
            
            # ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•œ ë°ì´í„° êµ¬ì¡°í™” (ë°˜ì˜¬ë¦¼ëœ ì¢Œí‘œ í‚¤ ì‚¬ìš© ê°€ëŠ¥ì„± ì²´í¬)
            # KD-TreeëŠ” ì˜¤ë²„í—¤ë“œê°€ í´ ìˆ˜ ìˆìœ¼ë‹ˆ, ë‹¨ìˆœ ê±°ë¦¬ ê³„ì‚° (ë°ì´í„°ê°€ ì•„ì£¼ ë§ì§€ ì•Šë‹¤ê³  ê°€ì •)
            # ìµœì í™”: 0.001ë„(ì•½ 100m) ë‹¨ìœ„ ë¡œ ê²©ìí™”í•˜ì—¬ ê²€ìƒ‰ ëŒ€ìƒ ì¶•ì†Œ
            spatial_index = {}
            for rec in cached_records:
                # DBì—ì„œ ê°€ì ¸ì˜¨ Decimal íƒ€ì…ì„ floatìœ¼ë¡œ ë³€í™˜
                r_lat = float(rec.latitude)
                r_lon = float(rec.longitude)
                r_elev = float(rec.elevation)
                
                # 100m ê·¸ë¦¬ë“œ í‚¤
                lat_idx = int(r_lat * 1000)
                lon_idx = int(r_lon * 1000)
                key = (lat_idx, lon_idx)
                
                if key not in spatial_index:
                    spatial_index[key] = []
                spatial_index[key].append((r_lat, r_lon, r_elev))

            # ê° ìš”ì²­ ì¢Œí‘œì— ëŒ€í•´ ê°€ì¥ ê°€ê¹Œìš´ ìºì‹œ ì°¾ê¸°
            hit_count_log = 0
            
            for lat, lon in seoul_grids:
                found_elevation = None
                min_dist = float('inf')
                
                # ê²€ìƒ‰í•  ì¸ì ‘ ê·¸ë¦¬ë“œ í‚¤ë“¤ (ìì‹  + ì£¼ë³€ 8ë°©í–¥)
                base_lat_idx = int(lat * 1000)
                base_lon_idx = int(lon * 1000)
                
                candidate_points = []
                for d_lat in [-1, 0, 1]:
                    for d_lon in [-1, 0, 1]:
                        k = (base_lat_idx + d_lat, base_lon_idx + d_lon)
                        if k in spatial_index:
                            candidate_points.extend(spatial_index[k])
                
                # í›„ë³´êµ° ì¤‘ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì  ì°¾ê¸°
                for c_lat, c_lon, c_elev in candidate_points:
                    # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê·¼ì‚¬ (ì†ë„ ìµœì í™”)
                    # ìœ„ë„ 1ë„ â‰ˆ 111km, ê²½ë„ 1ë„ â‰ˆ 88.8km (ì„œìš¸ ê¸°ì¤€)
                    dy = (lat - c_lat) * 111000
                    dx = (lon - c_lon) * 88800
                    dist = (dx*dx + dy*dy) ** 0.5
                    
                    if dist < min_dist:
                        min_dist = dist
                        found_elevation = c_elev
                
                # í—ˆìš© ì˜¤ì°¨: 45m (50m ê²©ìì˜ ëŒ€ê°ì„  ì ˆë°˜ 35.35m ì»¤ë²„ + ì—¬ìœ )
                if found_elevation is not None and min_dist <= 45:
                    cache_hits[(lat, lon)] = found_elevation
                    hit_count_log += 1
                else:
                    cache_misses.append((lat, lon))
            
            # ğŸ“Š ìºì‹œ íˆíŠ¸ìœ¨ ë¡œê¹…
            total_requests = len(seoul_grids)
            hit_rate = (hit_count_log / total_requests * 100) if total_requests > 0 else 0
            # logger.info(f"ğŸ“Š Nearest Cache Hit Rate: {hit_rate:.1f}% ({hit_count_log}/{total_requests} hits, {len(cache_misses)} misses)")
            
        else:
            cache_hits = {}
            # ì„œìš¸ ë°–ì´ë©´ ì „ì²´ê°€ ë¯¸ìŠ¤ (ë‹¨, ì„œìš¸ ë°–ì€ API í˜¸ì¶œ ëŒ€ìƒì´ ì•„ë‹ ìˆ˜ë„ ìˆìŒ. ë¡œì§ í™•ì¸ í•„ìš”)
            # ì—¬ê¸°ì„œëŠ” unique_gridsê°€ ì„œìš¸ ë°–ì¸ ê²½ìš° cache_missesì— ì¶”ê°€ë˜ì–´ API í˜¸ì¶œë¨ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            # ë‹¨, is_in_seoul ì²´í¬ê°€ ìœ„ì—ì„œ ìˆì—ˆìœ¼ë¯€ë¡œ ì„œìš¸ ë°–ì€ cache_missesì— ì•„ì˜ˆ ì•ˆ ë“¤ì–´ê°ˆ ìˆ˜ë„ ìˆìŒ.
            # ì›ë³¸ ë¡œì§ ìœ ì§€: ì„œìš¸ ì•„ë‹Œ ê³³ì€ API í˜¸ì¶œ (get_elevation ì°¸ì¡°)
            # í•˜ì§€ë§Œ ì—¬ê¸°ì„œ seoul_gridsë§Œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ, ì„œìš¸ ë°– ì¢Œí‘œëŠ” ëˆ„ë½ë  ìˆ˜ ìˆìŒ.
            # unique_grids ì „ì²´ë¥¼ ìˆœíšŒí•˜ë©° ì„œìš¸ ë°–ì€ ë°”ë¡œ cache_missesë¡œ?
            # -> ê¸°ì¡´ ì½”ë“œ: seoul_gridsë§Œ ìºì‹œ ë¡œì§ íƒœì›€.
            
            # ì„œìš¸ ë°– ì¢Œí‘œ ì²˜ë¦¬
            non_seoul = [gc for gc in unique_grids if not self.is_in_seoul(*gc)]
            cache_misses.extend(non_seoul)

        # 3. ê²°ê³¼ ë§µí•‘ (íˆíŠ¸ëœ ë°ì´í„°)
        for gc, elev in cache_hits.items():
            for orig in grid_map[gc]:
                results[orig] = elev
                
        # 4. ìºì‹œ ë¯¸ìŠ¤ ë¶„ëŸ‰ API í˜¸ì¶œ (ì¬í™œì„±í™”)
        if cache_misses:
            # logger.info(f"ğŸ“¡ Fetching {len(cache_misses)} missing points from Open-Meteo API...")
            
            try:
                # ë°°ì¹˜ í¬ê¸° ì œí•œ (500ê°œì”©) - Open-MeteoëŠ” ëŒ€ëŸ‰ ìš”ì²­ ì§€ì›
                batch_size = 500
                api_results = []
                
                for i in range(0, len(cache_misses), batch_size):
                    batch = cache_misses[i:i+batch_size]
                    # logger.info(f"  Batch {i//batch_size + 1}/{(len(cache_misses)-1)//batch_size + 1}: {len(batch)} points")
                    
                    try:
                        elevations = await self._fetch_batch_from_api(batch)
                        api_results.extend(zip(batch, elevations))
                        
                        # Rate limit ë°©ì§€: ë°°ì¹˜ ê°„ ëŒ€ê¸° (0.05s) - ë°°ì¹˜ ì‚¬ì´ì¦ˆ ëŠ˜ë ¤ì„œ í˜¸ì¶œ íšŸìˆ˜ ê°ì†Œ
                        if i + batch_size < len(cache_misses):
                            await asyncio.sleep(0.05)
                    except Exception as e:
                        logger.warning(f"  Batch failed: {e}, skipping...")
                        continue
                
                # ê²°ê³¼ ë§¤í•‘ ë° ì €ì¥
                if api_results:
                    # ê²°ê³¼ì— ì¶”ê°€
                    for coord, elev in api_results:
                        # ê·¸ë¦¬ë“œ ë§µì—ì„œ ì›ë³¸ ì¢Œí‘œë“¤ ì°¾ê¸°
                        if coord in grid_map:
                            for orig in grid_map[coord]:
                                results[orig] = elev
                    
                    # DBì— ì €ì¥
                    cache_items = [(lat, lon, elev) for (lat, lon), elev in api_results]
                    self._save_batch_to_cache(cache_items)
                    
                    # logger.info(f"âœ… Successfully fetched and cached {len(api_results)} new points")
                
            except Exception as e:
                logger.error(f"âŒ API batch fetch failed: {e}")
        
        return results
    
    
    def _get_from_cache(self, lat: float, lon: float) -> Optional[ElevationCache]:
        """
        ìºì‹œì—ì„œ ì¡°íšŒ (ì •í™•í•œ ì¢Œí‘œ ë§¤ì¹­)
        """
        # ê·¸ë¦¬ë”©ê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì¢Œí‘œ ë°˜ì˜¬ë¦¼ (11m ë‹¨ìœ„)
        lat_key = round(lat, 4)
        lon_key = round(lon, 4)
        
        return self.db.query(ElevationCache).filter(
            and_(
                ElevationCache.latitude == lat_key,
                ElevationCache.longitude == lon_key
            )
        ).first()
    
    
    def _save_to_cache(self, lat: float, lon: float, elevation: float):
        """
        ìºì‹œì— ì €ì¥ (ë³„ë„ ì„¸ì…˜ ì‚¬ìš©ìœ¼ë¡œ íŠ¸ëœì­ì…˜ ë…ë¦½ì„± ë³´ì¥)
        """
        from app.db.database import SessionLocal
        
        cache_db = SessionLocal()
        try:
            # ì¤‘ë³µ ì²´í¬
            existing = cache_db.query(ElevationCache).filter(
                and_(
                    ElevationCache.latitude == round(lat, 7),
                    ElevationCache.longitude == round(lon, 7)
                )
            ).first()
            
            if existing:
                existing.hit_count += 1
                cache_db.commit()
            else:
                cache_entry = ElevationCache(
                    latitude=round(lat, 7),
                    longitude=round(lon, 7),
                    elevation=round(elevation, 2)
                )
                cache_db.add(cache_entry)
                cache_db.commit()
        except Exception as e:
            cache_db.rollback()
            logger.warning(f"âŒ Cache save failed: {e}")
            # ìºì‹œ ì €ì¥ ì‹¤íŒ¨ëŠ” í¬ë¦¬í‹°ì»¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¡œê·¸ë§Œ ë‚¨ê¹€ (ì‚¬ìš©ì íë¦„ ë°©í•´ X)
        finally:
            cache_db.close()

    def _save_batch_to_cache(self, items: List[Tuple[float, float, float]]):
        """
        ëŒ€ëŸ‰ ê³ ë„ ë°ì´í„° ìºì‹œ ì €ì¥ (Bulk Insert) - ì¤‘ë³µ ë°©ì§€ ìµœì í™”
        Args:
            items: (lat, lon, elevation) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        if not items:
            return

        from app.db.database import SessionLocal
        
        cache_db = SessionLocal()
        try:
            # 1. ì…ë ¥ëœ ì¢Œí‘œë“¤ì˜ í‚¤ ì§‘í•© (ë°˜ì˜¬ë¦¼ ì²˜ë¦¬)
            # ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¤ì–´ì„œ ë‚˜ì¤‘ì— ê³ ë„ê°’ë„ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆê²Œ í•¨
            input_map = {
                (round(lat, 7), round(lon, 7)): round(elev, 2) 
                for lat, lon, elev in items
            }
            
            if not input_map:
                return

            # 2. DBì—ì„œ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì¢Œí‘œ ì¡°íšŒ (Bulk ì¡°íšŒ)
            existing_records = cache_db.query(ElevationCache.latitude, ElevationCache.longitude).filter(
                tuple_(ElevationCache.latitude, ElevationCache.longitude).in_(input_map.keys())
            ).all()
            
            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì¢Œí‘œ ì§‘í•©
            existing_coords = set((float(r.latitude), float(r.longitude)) for r in existing_records)
            
            # 3. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìƒˆë¡œìš´ ë°ì´í„°ë§Œ í•„í„°ë§
            new_objects = []
            for (lat, lon), elev in input_map.items():
                # DBì—ì„œ ê°€ì ¸ì˜¨ ê°’ì€ float ë³€í™˜ í•„ìš” (Decimal ë“±ìœ¼ë¡œ ì˜¬ ìˆ˜ ìˆìŒ)
                # ìœ„ì—ì„œ ì´ë¯¸ floatìœ¼ë¡œ ë³€í™˜í•´ì„œ setì— ë„£ì—ˆìœ¼ë¯€ë¡œ ë°”ë¡œ ë¹„êµ ê°€ëŠ¥
                # ë‹¨, ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ ê³ ë ¤í•˜ì—¬ round ì²˜ë¦¬ëœ ê°’ë¼ë¦¬ ë¹„êµ
                if (lat, lon) not in existing_coords:
                    new_objects.append(
                        ElevationCache(
                            latitude=lat,
                            longitude=lon,
                            elevation=elev
                        )
                    )
            
            # 4. ì •ë§ë¡œ ìƒˆë¡œìš´ ë°ì´í„°ë§Œ Bulk Insert
            if new_objects:
                cache_db.bulk_save_objects(new_objects)
                cache_db.commit()
                # logger.info(f"âœ… Bulk saved {len(new_objects)} new elevation points to cache (skipped {len(items) - len(new_objects)} duplicates)")
            else:
                # logger.info(f"â„¹ï¸ All {len(items)} points already exist in cache. Skipping save.")
                pass
            
        except Exception as e:
            cache_db.rollback()
            logger.warning(f"âš ï¸ Bulk save failed: {e}")
        finally:
            cache_db.close()
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((httpx.TimeoutException, httpx.ConnectError)),
        reraise=True
    )
    async def _fetch_batch_from_api(self, coordinates: List[Tuple[float, float]]) -> List[float]:
        """Open-Meteo APIì—ì„œ ë‹¤ì¤‘ ì¢Œí‘œ ê³ ë„ ì¡°íšŒ"""
        if not coordinates:
            return []
            
        url = "https://api.open-meteo.com/v1/elevation"
        
        # ì¢Œí‘œ ëª©ë¡ì„ ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ë³€í™˜
        lats = [str(lat) for lat, lon in coordinates]
        lons = [str(lon) for lat, lon in coordinates]
        
        params = {
            "latitude": ",".join(lats),
            "longitude": ",".join(lons)
        }
        
        client = await self.get_client()
        
        try:
            response = await client.get(url, params=params, timeout=20.0) # ë°°ì¹˜ë¼ ì‹œê°„ ì¢€ ë” ì¤Œ
            response.raise_for_status()
            
            data = response.json()
            elevations = data.get("elevation", [])
            
            if not elevations:
                raise ExternalAPIException("Open-Meteo returned no data")
                
            if len(elevations) != len(coordinates):
                raise ExternalAPIException(f"Open-Meteo data mismatch: requested {len(coordinates)}, got {len(elevations)}")
                
            return [float(e) for e in elevations]
            
        except httpx.HTTPStatusError as e:
            logger.error(f"Open-Meteo API HTTP error: {e.response.status_code}")
            raise ExternalAPIException(f"Elevation fetch failed: HTTP {e.response.status_code}")
        except Exception as e:
            logger.error(f"Open-Meteo API error: {e}")
            raise # ì˜ˆì™¸ ì „íŒŒ
